{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taller 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicados: 0\n",
      "Valores faltantes por columna:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "target      0\n",
      "dtype: int64\n",
      "Resumen estadístico:\n",
      "              age         sex          cp    trestbps        chol         fbs  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean    54.594059    0.676568    3.108911  131.785479  246.547855    0.148515   \n",
      "std      9.016370    0.468560    1.028414   17.748338   52.175933    0.356198   \n",
      "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
      "25%     48.000000    0.000000    2.000000  120.000000  211.000000    0.000000   \n",
      "50%     56.000000    1.000000    3.000000  130.000000  241.000000    0.000000   \n",
      "75%     61.000000    1.000000    4.000000  140.000000  275.000000    0.000000   \n",
      "max     77.000000    1.000000    4.000000  200.000000  564.000000    1.000000   \n",
      "\n",
      "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
      "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
      "mean     0.990099  149.194719    0.326733    1.057756    1.590759    0.683168   \n",
      "std      0.988293   23.173368    0.469794    1.165025    0.617767    0.937773   \n",
      "min      0.000000   71.000000    0.000000    0.000000    1.000000    0.000000   \n",
      "25%      0.000000  132.000000    0.000000    0.000000    1.000000    0.000000   \n",
      "50%      1.000000  152.000000    0.000000    0.800000    2.000000    0.000000   \n",
      "75%      2.000000  165.500000    1.000000    1.600000    2.000000    1.000000   \n",
      "max      2.000000  202.000000    1.000000    6.200000    3.000000    3.000000   \n",
      "\n",
      "           target  \n",
      "count  303.000000  \n",
      "mean     0.273927  \n",
      "std      0.446710  \n",
      "min      0.000000  \n",
      "25%      0.000000  \n",
      "50%      0.000000  \n",
      "75%      1.000000  \n",
      "max      1.000000  \n",
      "Tipos de datos originales:\n",
      "age           int64\n",
      "sex           int64\n",
      "cp            int64\n",
      "trestbps      int64\n",
      "chol          int64\n",
      "fbs           int64\n",
      "restecg       int64\n",
      "thalach       int64\n",
      "exang         int64\n",
      "oldpeak     float64\n",
      "slope         int64\n",
      "ca            int64\n",
      "thal         object\n",
      "target        int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/lauracalderon/Desktop/SÉPTIMO SEMESTRE/Analítica Computacional/Taller 7/Taller7_analitica/heart.csv')\n",
    "\n",
    "# 1. Verificar duplicados\n",
    "duplicados = df.duplicated().sum()\n",
    "print(f'Duplicados: {duplicados}')\n",
    "\n",
    "# 2. Identificar valores faltantes\n",
    "faltantes = df.isnull().sum()\n",
    "print('Valores faltantes por columna:')\n",
    "print(faltantes)\n",
    "\n",
    "# 3. Resumen estadístico para identificar posibles valores anómalos\n",
    "print('Resumen estadístico:')\n",
    "print(df.describe())\n",
    "\n",
    "# 4. Revisar las columnas que son categóricas y convertirlas en el tipo adecuado\n",
    "print('Tipos de datos originales:')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpieza de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7373 - loss: 0.6192 - val_accuracy: 0.7755 - val_loss: 0.6014\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7983 - loss: 0.5940 - val_accuracy: 0.7755 - val_loss: 0.5830\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7488 - loss: 0.5845 - val_accuracy: 0.7755 - val_loss: 0.5664\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7567 - loss: 0.5642 - val_accuracy: 0.7755 - val_loss: 0.5499\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7461 - loss: 0.5528 - val_accuracy: 0.7755 - val_loss: 0.5335\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7592 - loss: 0.5597 - val_accuracy: 0.7755 - val_loss: 0.5195\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7757 - loss: 0.5252 - val_accuracy: 0.7755 - val_loss: 0.5058\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7600 - loss: 0.5044 - val_accuracy: 0.7755 - val_loss: 0.4918\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7585 - loss: 0.4870 - val_accuracy: 0.7755 - val_loss: 0.4820\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7609 - loss: 0.4906 - val_accuracy: 0.7755 - val_loss: 0.4699\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7660 - loss: 0.4870 - val_accuracy: 0.7959 - val_loss: 0.4577\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7746 - loss: 0.4754 - val_accuracy: 0.7959 - val_loss: 0.4460\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7586 - loss: 0.4611 - val_accuracy: 0.7959 - val_loss: 0.4348\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7955 - loss: 0.4449 - val_accuracy: 0.7959 - val_loss: 0.4231\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7738 - loss: 0.4289 - val_accuracy: 0.7959 - val_loss: 0.4129\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7810 - loss: 0.4286 - val_accuracy: 0.7959 - val_loss: 0.4067\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8135 - loss: 0.4024 - val_accuracy: 0.7959 - val_loss: 0.3983\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8063 - loss: 0.4017 - val_accuracy: 0.7959 - val_loss: 0.3900\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7746 - loss: 0.4407 - val_accuracy: 0.7959 - val_loss: 0.3820\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8072 - loss: 0.4116 - val_accuracy: 0.7959 - val_loss: 0.3750\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.3771 - val_accuracy: 0.7959 - val_loss: 0.3713\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8134 - loss: 0.3916 - val_accuracy: 0.7959 - val_loss: 0.3679\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8284 - loss: 0.3545 - val_accuracy: 0.7959 - val_loss: 0.3626\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8323 - loss: 0.3728 - val_accuracy: 0.7959 - val_loss: 0.3592\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8236 - loss: 0.3627 - val_accuracy: 0.7959 - val_loss: 0.3559\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7899 - loss: 0.3798 - val_accuracy: 0.7959 - val_loss: 0.3518\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8224 - loss: 0.3495 - val_accuracy: 0.7959 - val_loss: 0.3490\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8008 - loss: 0.3768 - val_accuracy: 0.7959 - val_loss: 0.3459\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7937 - loss: 0.3734 - val_accuracy: 0.7959 - val_loss: 0.3423\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8291 - loss: 0.3289 - val_accuracy: 0.7959 - val_loss: 0.3386\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8153 - loss: 0.3657 - val_accuracy: 0.7959 - val_loss: 0.3315\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8199 - loss: 0.3602 - val_accuracy: 0.7959 - val_loss: 0.3261\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8061 - loss: 0.3590 - val_accuracy: 0.7959 - val_loss: 0.3221\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8069 - loss: 0.3699 - val_accuracy: 0.8163 - val_loss: 0.3184\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8316 - loss: 0.3237 - val_accuracy: 0.8163 - val_loss: 0.3154\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8560 - loss: 0.3250 - val_accuracy: 0.8163 - val_loss: 0.3130\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8557 - loss: 0.3162 - val_accuracy: 0.8163 - val_loss: 0.3105\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8726 - loss: 0.2879 - val_accuracy: 0.8163 - val_loss: 0.3085\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8303 - loss: 0.3572 - val_accuracy: 0.8367 - val_loss: 0.3056\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8069 - loss: 0.3510 - val_accuracy: 0.8367 - val_loss: 0.3017\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8662 - loss: 0.2939 - val_accuracy: 0.8571 - val_loss: 0.2986\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8292 - loss: 0.3202 - val_accuracy: 0.8776 - val_loss: 0.2958\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8572 - loss: 0.3043 - val_accuracy: 0.8776 - val_loss: 0.2914\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8578 - loss: 0.2832 - val_accuracy: 0.8776 - val_loss: 0.2883\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8110 - loss: 0.3314 - val_accuracy: 0.8776 - val_loss: 0.2854\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8378 - loss: 0.3206 - val_accuracy: 0.8776 - val_loss: 0.2833\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8429 - loss: 0.3012 - val_accuracy: 0.8776 - val_loss: 0.2821\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8386 - loss: 0.2976 - val_accuracy: 0.8776 - val_loss: 0.2812\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8314 - loss: 0.3025 - val_accuracy: 0.8776 - val_loss: 0.2795\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.2992 - val_accuracy: 0.8776 - val_loss: 0.2775\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step\n",
      "Accuracy: 0.8360655737704918\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.6875\n"
     ]
    }
   ],
   "source": [
    "selected_features = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', \n",
    "                     'exang', 'oldpeak', 'slope', 'ca', 'thal','target']\n",
    "df = df[selected_features]\n",
    "\n",
    "# 1. Definir columnas categóricas y numéricas\n",
    "num_features = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', 'ca']  \n",
    "cat_features = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'thal']\n",
    "\n",
    "# 2. Preprocesamiento de variables\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num_features),\n",
    "        ('cat', OneHotEncoder(), cat_features) \n",
    "    ]\n",
    ") \n",
    "\n",
    "# 3. Separar características (X) y etiquetas (y)\n",
    "X = df.drop(columns='target')\n",
    "y = df['target']\n",
    "\n",
    "# 4. Aplicar transformación a los datos\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# 5. Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Crear el modelo de red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "# 7. Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 8. Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "# 9. Graficar la pérdida de entrenamiento y validación\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.title('Pérdida del Modelo')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Pérdida')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 10. Hacer predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(\"int32\")\n",
    "\n",
    "# 11. Calcular y mostrar las métricas de rendimiento\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Modificar el optimizador empleado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Modificación: Usar RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.7291 - loss: 0.6034 - val_accuracy: 0.7551 - val_loss: 0.5405\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7014 - loss: 0.6046 - val_accuracy: 0.7551 - val_loss: 0.5265\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6897 - loss: 0.5896 - val_accuracy: 0.7551 - val_loss: 0.5199\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7317 - loss: 0.5620 - val_accuracy: 0.7551 - val_loss: 0.5119\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7501 - loss: 0.5650 - val_accuracy: 0.7551 - val_loss: 0.5024\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7450 - loss: 0.5589 - val_accuracy: 0.7551 - val_loss: 0.4932\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7681 - loss: 0.5276 - val_accuracy: 0.7551 - val_loss: 0.4851\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7998 - loss: 0.4959 - val_accuracy: 0.7551 - val_loss: 0.4741\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7723 - loss: 0.4971 - val_accuracy: 0.7551 - val_loss: 0.4650\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7772 - loss: 0.5111 - val_accuracy: 0.7755 - val_loss: 0.4536\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7784 - loss: 0.4761 - val_accuracy: 0.7755 - val_loss: 0.4475\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7707 - loss: 0.4932 - val_accuracy: 0.7755 - val_loss: 0.4392\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7865 - loss: 0.4911 - val_accuracy: 0.7755 - val_loss: 0.4297\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7493 - loss: 0.4905 - val_accuracy: 0.7755 - val_loss: 0.4217\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7669 - loss: 0.4482 - val_accuracy: 0.7959 - val_loss: 0.4136\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7646 - loss: 0.4687 - val_accuracy: 0.8163 - val_loss: 0.4071\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7593 - loss: 0.4631 - val_accuracy: 0.8163 - val_loss: 0.3995\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7850 - loss: 0.4157 - val_accuracy: 0.8163 - val_loss: 0.3920\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8252 - loss: 0.4135 - val_accuracy: 0.8163 - val_loss: 0.3843\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8010 - loss: 0.4109 - val_accuracy: 0.8163 - val_loss: 0.3756\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8103 - loss: 0.4053 - val_accuracy: 0.8163 - val_loss: 0.3710\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8456 - loss: 0.3725 - val_accuracy: 0.8163 - val_loss: 0.3688\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8097 - loss: 0.3978 - val_accuracy: 0.8163 - val_loss: 0.3638\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8382 - loss: 0.3737 - val_accuracy: 0.8163 - val_loss: 0.3589\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8420 - loss: 0.3609 - val_accuracy: 0.8367 - val_loss: 0.3554\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8043 - loss: 0.3861 - val_accuracy: 0.8163 - val_loss: 0.3535\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8266 - loss: 0.3704 - val_accuracy: 0.8367 - val_loss: 0.3478\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7804 - loss: 0.4202 - val_accuracy: 0.8367 - val_loss: 0.3437\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8298 - loss: 0.3543 - val_accuracy: 0.8367 - val_loss: 0.3395\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8136 - loss: 0.3517 - val_accuracy: 0.8367 - val_loss: 0.3369\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8356 - loss: 0.3575 - val_accuracy: 0.8571 - val_loss: 0.3310\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8162 - loss: 0.3477 - val_accuracy: 0.8367 - val_loss: 0.3265\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8157 - loss: 0.3654 - val_accuracy: 0.8367 - val_loss: 0.3220\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8270 - loss: 0.3571 - val_accuracy: 0.8571 - val_loss: 0.3167\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8691 - loss: 0.3222 - val_accuracy: 0.8571 - val_loss: 0.3127\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8481 - loss: 0.3087 - val_accuracy: 0.8571 - val_loss: 0.3049\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8624 - loss: 0.3098 - val_accuracy: 0.8571 - val_loss: 0.3025\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8857 - loss: 0.2911 - val_accuracy: 0.8367 - val_loss: 0.2978\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8765 - loss: 0.2935 - val_accuracy: 0.8367 - val_loss: 0.2963\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8716 - loss: 0.3132 - val_accuracy: 0.8367 - val_loss: 0.2905\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8766 - loss: 0.2934 - val_accuracy: 0.8367 - val_loss: 0.2900\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8776 - loss: 0.2930 - val_accuracy: 0.8367 - val_loss: 0.2885\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8551 - loss: 0.3011 - val_accuracy: 0.8367 - val_loss: 0.2866\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8901 - loss: 0.2822 - val_accuracy: 0.8571 - val_loss: 0.2800\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8657 - loss: 0.2807 - val_accuracy: 0.8571 - val_loss: 0.2786\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8981 - loss: 0.2565 - val_accuracy: 0.8571 - val_loss: 0.2782\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8868 - loss: 0.2759 - val_accuracy: 0.8571 - val_loss: 0.2769\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8784 - loss: 0.2728 - val_accuracy: 0.8367 - val_loss: 0.2785\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8694 - loss: 0.3104 - val_accuracy: 0.8776 - val_loss: 0.2746\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8948 - loss: 0.2585 - val_accuracy: 0.8776 - val_loss: 0.2706\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Resultados con RMSprop:\n",
      "Accuracy: 0.8688524590163934\n",
      "Precision: 0.7647058823529411\n",
      "Recall: 0.7647058823529411\n",
      "F1 Score: 0.7647058823529411\n"
     ]
    }
   ],
   "source": [
    "model_rmsprop = Sequential()\n",
    "model_rmsprop.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_rmsprop.add(Dense(8, activation='relu'))\n",
    "model_rmsprop.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_rmsprop.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_rmsprop = model_rmsprop.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_rmsprop = model_rmsprop.predict(X_test)\n",
    "y_pred_classes_rmsprop = (y_pred_rmsprop > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con RMSprop:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_rmsprop)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_rmsprop)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_rmsprop)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_rmsprop)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Modificación: Usar SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 0.4067 - loss: 0.7866 - val_accuracy: 0.4694 - val_loss: 0.7526\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4192 - loss: 0.7562 - val_accuracy: 0.4898 - val_loss: 0.7214\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4598 - loss: 0.7313 - val_accuracy: 0.5306 - val_loss: 0.6971\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4669 - loss: 0.7203 - val_accuracy: 0.5714 - val_loss: 0.6795\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5527 - loss: 0.6885 - val_accuracy: 0.6531 - val_loss: 0.6668\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5983 - loss: 0.6639 - val_accuracy: 0.6735 - val_loss: 0.6521\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5977 - loss: 0.6637 - val_accuracy: 0.6735 - val_loss: 0.6420\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6338 - loss: 0.6548 - val_accuracy: 0.6939 - val_loss: 0.6325\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6766 - loss: 0.6422 - val_accuracy: 0.7347 - val_loss: 0.6200\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6317 - loss: 0.6383 - val_accuracy: 0.7347 - val_loss: 0.6081\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6532 - loss: 0.6308 - val_accuracy: 0.7551 - val_loss: 0.5956\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6640 - loss: 0.6150 - val_accuracy: 0.7755 - val_loss: 0.5862\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7160 - loss: 0.6047 - val_accuracy: 0.7755 - val_loss: 0.5788\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7169 - loss: 0.5964 - val_accuracy: 0.7551 - val_loss: 0.5696\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6943 - loss: 0.5961 - val_accuracy: 0.7755 - val_loss: 0.5633\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7127 - loss: 0.5841 - val_accuracy: 0.7755 - val_loss: 0.5545\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7090 - loss: 0.5810 - val_accuracy: 0.7755 - val_loss: 0.5499\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7140 - loss: 0.5837 - val_accuracy: 0.7959 - val_loss: 0.5440\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7679 - loss: 0.5533 - val_accuracy: 0.8163 - val_loss: 0.5362\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7488 - loss: 0.5656 - val_accuracy: 0.8163 - val_loss: 0.5331\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.5722 - val_accuracy: 0.7959 - val_loss: 0.5243\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7442 - loss: 0.5476 - val_accuracy: 0.7959 - val_loss: 0.5163\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 0.5444 - val_accuracy: 0.7959 - val_loss: 0.5109\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7423 - loss: 0.5271 - val_accuracy: 0.7959 - val_loss: 0.5056\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7459 - loss: 0.5190 - val_accuracy: 0.7959 - val_loss: 0.5006\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7210 - loss: 0.5174 - val_accuracy: 0.7959 - val_loss: 0.4936\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.5193 - val_accuracy: 0.8163 - val_loss: 0.4868\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7349 - loss: 0.5088 - val_accuracy: 0.7959 - val_loss: 0.4837\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7199 - loss: 0.5184 - val_accuracy: 0.8163 - val_loss: 0.4772\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7422 - loss: 0.4993 - val_accuracy: 0.8163 - val_loss: 0.4700\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7072 - loss: 0.5192 - val_accuracy: 0.8163 - val_loss: 0.4632\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7401 - loss: 0.4920 - val_accuracy: 0.8163 - val_loss: 0.4560\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7503 - loss: 0.4715 - val_accuracy: 0.8367 - val_loss: 0.4501\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7128 - loss: 0.4853 - val_accuracy: 0.8367 - val_loss: 0.4458\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7443 - loss: 0.4627 - val_accuracy: 0.8367 - val_loss: 0.4400\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7407 - loss: 0.4689 - val_accuracy: 0.8367 - val_loss: 0.4352\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7157 - loss: 0.4803 - val_accuracy: 0.8367 - val_loss: 0.4302\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7357 - loss: 0.4612 - val_accuracy: 0.8367 - val_loss: 0.4282\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7298 - loss: 0.4745 - val_accuracy: 0.8367 - val_loss: 0.4222\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7335 - loss: 0.4628 - val_accuracy: 0.8367 - val_loss: 0.4209\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7167 - loss: 0.4727 - val_accuracy: 0.8367 - val_loss: 0.4165\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7334 - loss: 0.4689 - val_accuracy: 0.8367 - val_loss: 0.4123\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7427 - loss: 0.4595 - val_accuracy: 0.8367 - val_loss: 0.4083\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.4633 - val_accuracy: 0.8367 - val_loss: 0.4040\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7325 - loss: 0.4705 - val_accuracy: 0.8367 - val_loss: 0.4002\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7438 - loss: 0.4370 - val_accuracy: 0.8367 - val_loss: 0.3964\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7520 - loss: 0.4340 - val_accuracy: 0.8367 - val_loss: 0.3932\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7452 - loss: 0.4438 - val_accuracy: 0.8367 - val_loss: 0.3898\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7353 - loss: 0.4475 - val_accuracy: 0.8367 - val_loss: 0.3862\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7107 - loss: 0.4565 - val_accuracy: 0.8367 - val_loss: 0.3829\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Resultados con SGD:\n",
      "Accuracy: 0.7868852459016393\n",
      "Precision: 0.75\n",
      "Recall: 0.35294117647058826\n",
      "F1 Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "model_sgd = Sequential()\n",
    "model_sgd.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_sgd.add(Dense(8, activation='relu'))\n",
    "model_sgd.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_sgd.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_sgd = model_sgd.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_sgd = model_sgd.predict(X_test)\n",
    "y_pred_classes_sgd = (y_pred_sgd > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con SGD:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_sgd)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_sgd)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_sgd)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_sgd)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modifique la tasa de aprendizaje del optimizador empleado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.7204 - loss: 0.5972 - val_accuracy: 0.7755 - val_loss: 0.5901\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7347 - loss: 0.5947 - val_accuracy: 0.7755 - val_loss: 0.5880\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6987 - loss: 0.6012 - val_accuracy: 0.7755 - val_loss: 0.5858\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 0.6029 - val_accuracy: 0.7755 - val_loss: 0.5838\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7116 - loss: 0.5933 - val_accuracy: 0.7755 - val_loss: 0.5819\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.5822 - val_accuracy: 0.7755 - val_loss: 0.5799\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7179 - loss: 0.5968 - val_accuracy: 0.7755 - val_loss: 0.5780\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7196 - loss: 0.5936 - val_accuracy: 0.7755 - val_loss: 0.5761\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7370 - loss: 0.5754 - val_accuracy: 0.7755 - val_loss: 0.5743\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7358 - loss: 0.5801 - val_accuracy: 0.7755 - val_loss: 0.5722\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7226 - loss: 0.5777 - val_accuracy: 0.7755 - val_loss: 0.5705\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 0.5808 - val_accuracy: 0.7755 - val_loss: 0.5687\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7151 - loss: 0.5746 - val_accuracy: 0.7755 - val_loss: 0.5669\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.5727 - val_accuracy: 0.7755 - val_loss: 0.5651\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7142 - loss: 0.5857 - val_accuracy: 0.7755 - val_loss: 0.5632\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7123 - loss: 0.5886 - val_accuracy: 0.7755 - val_loss: 0.5611\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7170 - loss: 0.5832 - val_accuracy: 0.7755 - val_loss: 0.5592\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 0.5791 - val_accuracy: 0.7755 - val_loss: 0.5574\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7190 - loss: 0.5694 - val_accuracy: 0.7755 - val_loss: 0.5556\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7289 - loss: 0.5546 - val_accuracy: 0.7755 - val_loss: 0.5540\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7324 - loss: 0.5575 - val_accuracy: 0.7755 - val_loss: 0.5523\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7071 - loss: 0.5670 - val_accuracy: 0.7755 - val_loss: 0.5507\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7168 - loss: 0.5751 - val_accuracy: 0.7755 - val_loss: 0.5491\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7213 - loss: 0.5610 - val_accuracy: 0.7755 - val_loss: 0.5476\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7217 - loss: 0.5673 - val_accuracy: 0.7755 - val_loss: 0.5460\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6858 - loss: 0.5793 - val_accuracy: 0.7755 - val_loss: 0.5450\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.5576 - val_accuracy: 0.7755 - val_loss: 0.5436\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7323 - loss: 0.5465 - val_accuracy: 0.7755 - val_loss: 0.5421\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7083 - loss: 0.5677 - val_accuracy: 0.7755 - val_loss: 0.5406\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7297 - loss: 0.5341 - val_accuracy: 0.7755 - val_loss: 0.5389\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7174 - loss: 0.5571 - val_accuracy: 0.7755 - val_loss: 0.5373\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7323 - loss: 0.5395 - val_accuracy: 0.7755 - val_loss: 0.5361\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7155 - loss: 0.5532 - val_accuracy: 0.7755 - val_loss: 0.5347\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7172 - loss: 0.5469 - val_accuracy: 0.7755 - val_loss: 0.5331\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7134 - loss: 0.5435 - val_accuracy: 0.7755 - val_loss: 0.5316\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6954 - loss: 0.5625 - val_accuracy: 0.7755 - val_loss: 0.5302\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7515 - loss: 0.5311 - val_accuracy: 0.7755 - val_loss: 0.5286\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6970 - loss: 0.5537 - val_accuracy: 0.7755 - val_loss: 0.5269\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7019 - loss: 0.5536 - val_accuracy: 0.7755 - val_loss: 0.5251\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7011 - loss: 0.5427 - val_accuracy: 0.7755 - val_loss: 0.5235\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7123 - loss: 0.5304 - val_accuracy: 0.7755 - val_loss: 0.5220\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7550 - loss: 0.5070 - val_accuracy: 0.7755 - val_loss: 0.5202\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7216 - loss: 0.5206 - val_accuracy: 0.7755 - val_loss: 0.5186\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7249 - loss: 0.5349 - val_accuracy: 0.7755 - val_loss: 0.5172\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7329 - loss: 0.5263 - val_accuracy: 0.7755 - val_loss: 0.5156\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7660 - loss: 0.4929 - val_accuracy: 0.7755 - val_loss: 0.5141\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7348 - loss: 0.5131 - val_accuracy: 0.7755 - val_loss: 0.5125\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7594 - loss: 0.4992 - val_accuracy: 0.7755 - val_loss: 0.5108\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6998 - loss: 0.5472 - val_accuracy: 0.7755 - val_loss: 0.5093\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7038 - loss: 0.5276 - val_accuracy: 0.7755 - val_loss: 0.5078\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Resultados con learning_rate=0.0001:\n",
      "Accuracy: 0.7540983606557377\n",
      "Precision: 1.0\n",
      "Recall: 0.11764705882352941\n",
      "F1 Score: 0.21052631578947367\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model_lr_low = Sequential()\n",
    "model_lr_low.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_lr_low.add(Dense(8, activation='relu'))\n",
    "model_lr_low.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "optimizer_lr_low = Adam(learning_rate=0.0001)\n",
    "model_lr_low.compile(optimizer=optimizer_lr_low, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_lr_low = model_lr_low.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_lr_low = model_lr_low.predict(X_test)\n",
    "y_pred_classes_lr_low = (y_pred_lr_low > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con learning_rate=0.0001:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_lr_low)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_lr_low)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_lr_low)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_lr_low)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.5704 - loss: 0.6751 - val_accuracy: 0.7347 - val_loss: 0.5867\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6203 - loss: 0.6731 - val_accuracy: 0.7755 - val_loss: 0.5654\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6937 - loss: 0.6274 - val_accuracy: 0.7959 - val_loss: 0.5469\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6737 - loss: 0.6259 - val_accuracy: 0.7959 - val_loss: 0.5298\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 0.6064 - val_accuracy: 0.7959 - val_loss: 0.5155\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7374 - loss: 0.5752 - val_accuracy: 0.7959 - val_loss: 0.5032\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7359 - loss: 0.5731 - val_accuracy: 0.7959 - val_loss: 0.4934\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7268 - loss: 0.5903 - val_accuracy: 0.7959 - val_loss: 0.4871\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7849 - loss: 0.5507 - val_accuracy: 0.8163 - val_loss: 0.4794\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7524 - loss: 0.5581 - val_accuracy: 0.8163 - val_loss: 0.4703\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7899 - loss: 0.5494 - val_accuracy: 0.8163 - val_loss: 0.4626\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8134 - loss: 0.5097 - val_accuracy: 0.8163 - val_loss: 0.4542\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8015 - loss: 0.5255 - val_accuracy: 0.8163 - val_loss: 0.4451\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7904 - loss: 0.5220 - val_accuracy: 0.8163 - val_loss: 0.4356\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7913 - loss: 0.5077 - val_accuracy: 0.8163 - val_loss: 0.4258\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7906 - loss: 0.4883 - val_accuracy: 0.8163 - val_loss: 0.4164\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7791 - loss: 0.4837 - val_accuracy: 0.8163 - val_loss: 0.4069\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7661 - loss: 0.4842 - val_accuracy: 0.8163 - val_loss: 0.3974\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7573 - loss: 0.4815 - val_accuracy: 0.8163 - val_loss: 0.3876\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7572 - loss: 0.4747 - val_accuracy: 0.8776 - val_loss: 0.3762\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8034 - loss: 0.4311 - val_accuracy: 0.8571 - val_loss: 0.3659\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7871 - loss: 0.4203 - val_accuracy: 0.8571 - val_loss: 0.3566\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7741 - loss: 0.4567 - val_accuracy: 0.8571 - val_loss: 0.3484\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7756 - loss: 0.4400 - val_accuracy: 0.8571 - val_loss: 0.3411\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.4304 - val_accuracy: 0.8571 - val_loss: 0.3335\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8180 - loss: 0.3837 - val_accuracy: 0.8571 - val_loss: 0.3282\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7909 - loss: 0.4041 - val_accuracy: 0.8571 - val_loss: 0.3228\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7890 - loss: 0.4150 - val_accuracy: 0.8571 - val_loss: 0.3181\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8138 - loss: 0.3920 - val_accuracy: 0.8571 - val_loss: 0.3114\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8219 - loss: 0.3807 - val_accuracy: 0.8980 - val_loss: 0.3005\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8600 - loss: 0.3614 - val_accuracy: 0.8980 - val_loss: 0.2915\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8702 - loss: 0.3388 - val_accuracy: 0.8980 - val_loss: 0.2852\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8618 - loss: 0.3550 - val_accuracy: 0.8980 - val_loss: 0.2827\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8634 - loss: 0.3505 - val_accuracy: 0.8980 - val_loss: 0.2840\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8576 - loss: 0.3560 - val_accuracy: 0.8980 - val_loss: 0.2843\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8416 - loss: 0.3362 - val_accuracy: 0.8980 - val_loss: 0.2820\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8679 - loss: 0.3288 - val_accuracy: 0.8980 - val_loss: 0.2783\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8451 - loss: 0.3395 - val_accuracy: 0.8980 - val_loss: 0.2776\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8463 - loss: 0.3365 - val_accuracy: 0.8980 - val_loss: 0.2745\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8439 - loss: 0.3437 - val_accuracy: 0.8980 - val_loss: 0.2718\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8537 - loss: 0.3328 - val_accuracy: 0.8980 - val_loss: 0.2677\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8368 - loss: 0.3750 - val_accuracy: 0.8980 - val_loss: 0.2638\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.2832 - val_accuracy: 0.8980 - val_loss: 0.2599\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8623 - loss: 0.3384 - val_accuracy: 0.8776 - val_loss: 0.2552\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8658 - loss: 0.3276 - val_accuracy: 0.8776 - val_loss: 0.2550\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8718 - loss: 0.3106 - val_accuracy: 0.8776 - val_loss: 0.2598\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8738 - loss: 0.3050 - val_accuracy: 0.8776 - val_loss: 0.2628\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8927 - loss: 0.3164 - val_accuracy: 0.8776 - val_loss: 0.2559\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8997 - loss: 0.2891 - val_accuracy: 0.8776 - val_loss: 0.2539\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8820 - loss: 0.2860 - val_accuracy: 0.8776 - val_loss: 0.2543\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Resultados con learning_rate=0.001 (default):\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.7222222222222222\n",
      "Recall: 0.7647058823529411\n",
      "F1 Score: 0.7428571428571429\n"
     ]
    }
   ],
   "source": [
    "model_lr_default = Sequential()\n",
    "model_lr_default.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_lr_default.add(Dense(8, activation='relu'))\n",
    "model_lr_default.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer_lr_default = Adam(learning_rate=0.001)\n",
    "model_lr_default.compile(optimizer=optimizer_lr_default, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_lr_default = model_lr_default.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_lr_default = model_lr_default.predict(X_test)\n",
    "y_pred_classes_lr_default = (y_pred_lr_default > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con learning_rate=0.001 (default):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_lr_default)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_lr_default)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_lr_default)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_lr_default)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5449 - loss: 0.6955 - val_accuracy: 0.8367 - val_loss: 0.5559\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7762 - loss: 0.5575 - val_accuracy: 0.7959 - val_loss: 0.4287\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7668 - loss: 0.4426 - val_accuracy: 0.8571 - val_loss: 0.3306\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7518 - loss: 0.4128 - val_accuracy: 0.8980 - val_loss: 0.2749\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8669 - loss: 0.3177 - val_accuracy: 0.9184 - val_loss: 0.2553\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8888 - loss: 0.2898 - val_accuracy: 0.9184 - val_loss: 0.2491\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8590 - loss: 0.2860 - val_accuracy: 0.8980 - val_loss: 0.2474\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8843 - loss: 0.2668 - val_accuracy: 0.8776 - val_loss: 0.2526\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8794 - loss: 0.2475 - val_accuracy: 0.8776 - val_loss: 0.2591\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8463 - loss: 0.2729 - val_accuracy: 0.8776 - val_loss: 0.2615\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8617 - loss: 0.2655 - val_accuracy: 0.8776 - val_loss: 0.2696\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9029 - loss: 0.2323 - val_accuracy: 0.8367 - val_loss: 0.2908\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8977 - loss: 0.2245 - val_accuracy: 0.8571 - val_loss: 0.2920\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.1996 - val_accuracy: 0.8571 - val_loss: 0.2957\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8904 - loss: 0.2178 - val_accuracy: 0.8571 - val_loss: 0.3011\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9057 - loss: 0.1963 - val_accuracy: 0.8571 - val_loss: 0.3135\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9386 - loss: 0.1689 - val_accuracy: 0.8571 - val_loss: 0.3136\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9125 - loss: 0.1824 - val_accuracy: 0.8571 - val_loss: 0.3334\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9529 - loss: 0.1667 - val_accuracy: 0.8571 - val_loss: 0.3838\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9438 - loss: 0.1902 - val_accuracy: 0.8367 - val_loss: 0.3706\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9143 - loss: 0.1739 - val_accuracy: 0.8571 - val_loss: 0.3769\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9337 - loss: 0.1663 - val_accuracy: 0.8571 - val_loss: 0.3969\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9442 - loss: 0.1535 - val_accuracy: 0.8571 - val_loss: 0.4010\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9564 - loss: 0.1157 - val_accuracy: 0.8571 - val_loss: 0.3951\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9451 - loss: 0.1399 - val_accuracy: 0.8571 - val_loss: 0.4014\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9445 - loss: 0.1352 - val_accuracy: 0.8367 - val_loss: 0.4220\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9531 - loss: 0.1139 - val_accuracy: 0.8367 - val_loss: 0.4382\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9699 - loss: 0.1083 - val_accuracy: 0.8367 - val_loss: 0.4615\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1115 - val_accuracy: 0.8367 - val_loss: 0.4850\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9651 - loss: 0.1077 - val_accuracy: 0.8571 - val_loss: 0.4722\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9550 - loss: 0.0982 - val_accuracy: 0.8367 - val_loss: 0.4570\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9580 - loss: 0.1032 - val_accuracy: 0.8367 - val_loss: 0.4844\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9158 - loss: 0.1443 - val_accuracy: 0.7959 - val_loss: 0.5287\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9342 - loss: 0.1373 - val_accuracy: 0.8163 - val_loss: 0.5108\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9209 - loss: 0.1449 - val_accuracy: 0.8367 - val_loss: 0.5116\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9233 - loss: 0.1441 - val_accuracy: 0.8163 - val_loss: 0.5022\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9817 - loss: 0.0942 - val_accuracy: 0.8367 - val_loss: 0.4905\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9804 - loss: 0.1064 - val_accuracy: 0.8367 - val_loss: 0.4929\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9686 - loss: 0.0875 - val_accuracy: 0.8571 - val_loss: 0.5127\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9713 - loss: 0.0932 - val_accuracy: 0.8571 - val_loss: 0.5311\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9767 - loss: 0.0853 - val_accuracy: 0.8571 - val_loss: 0.5532\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9765 - loss: 0.0738 - val_accuracy: 0.8571 - val_loss: 0.5744\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9783 - loss: 0.0836 - val_accuracy: 0.8367 - val_loss: 0.5927\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9908 - loss: 0.0628 - val_accuracy: 0.8367 - val_loss: 0.6074\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9880 - loss: 0.0574 - val_accuracy: 0.8571 - val_loss: 0.6076\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0549 - val_accuracy: 0.8571 - val_loss: 0.6074\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9679 - loss: 0.0667 - val_accuracy: 0.8571 - val_loss: 0.5925\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9577 - loss: 0.0883 - val_accuracy: 0.8571 - val_loss: 0.5969\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9752 - loss: 0.0807 - val_accuracy: 0.8367 - val_loss: 0.6269\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9639 - loss: 0.0720 - val_accuracy: 0.8367 - val_loss: 0.6553\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
      "Resultados con learning_rate=0.01:\n",
      "Accuracy: 0.7540983606557377\n",
      "Precision: 0.5714285714285714\n",
      "Recall: 0.47058823529411764\n",
      "F1 Score: 0.5161290322580645\n"
     ]
    }
   ],
   "source": [
    "model_lr_high = Sequential()\n",
    "model_lr_high.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_lr_high.add(Dense(8, activation='relu'))\n",
    "model_lr_high.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "optimizer_lr_high = Adam(learning_rate=0.01)\n",
    "model_lr_high.compile(optimizer=optimizer_lr_high, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_lr_high = model_lr_high.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_lr_high = model_lr_high.predict(X_test)\n",
    "y_pred_classes_lr_high = (y_pred_lr_high > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con learning_rate=0.01:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_lr_high)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_lr_high)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_lr_high)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_lr_high)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Modifique el número de neuronas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Con menos neuronas: 8 y 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.1677 - loss: 0.9516 - val_accuracy: 0.1837 - val_loss: 0.9388\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2157 - loss: 0.9161 - val_accuracy: 0.2041 - val_loss: 0.9073\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2339 - loss: 0.8803 - val_accuracy: 0.2449 - val_loss: 0.8809\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2672 - loss: 0.8583 - val_accuracy: 0.2653 - val_loss: 0.8568\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3054 - loss: 0.8197 - val_accuracy: 0.2857 - val_loss: 0.8369\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3129 - loss: 0.8098 - val_accuracy: 0.3061 - val_loss: 0.8179\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3391 - loss: 0.7849 - val_accuracy: 0.3061 - val_loss: 0.8001\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3948 - loss: 0.7740 - val_accuracy: 0.3265 - val_loss: 0.7829\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3952 - loss: 0.7492 - val_accuracy: 0.3265 - val_loss: 0.7676\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4569 - loss: 0.7496 - val_accuracy: 0.3673 - val_loss: 0.7552\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4900 - loss: 0.7251 - val_accuracy: 0.3878 - val_loss: 0.7444\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5196 - loss: 0.7124 - val_accuracy: 0.4490 - val_loss: 0.7341\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5303 - loss: 0.7097 - val_accuracy: 0.4286 - val_loss: 0.7231\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5933 - loss: 0.6911 - val_accuracy: 0.5102 - val_loss: 0.7071\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5979 - loss: 0.6799 - val_accuracy: 0.6327 - val_loss: 0.6930\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6102 - loss: 0.6694 - val_accuracy: 0.6531 - val_loss: 0.6792\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6314 - loss: 0.6704 - val_accuracy: 0.6735 - val_loss: 0.6661\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6879 - loss: 0.6422 - val_accuracy: 0.6939 - val_loss: 0.6505\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7091 - loss: 0.6196 - val_accuracy: 0.7347 - val_loss: 0.6358\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7176 - loss: 0.6105 - val_accuracy: 0.7347 - val_loss: 0.6216\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6762 - loss: 0.6199 - val_accuracy: 0.7551 - val_loss: 0.6069\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6812 - loss: 0.6065 - val_accuracy: 0.7551 - val_loss: 0.5939\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7471 - loss: 0.5656 - val_accuracy: 0.7551 - val_loss: 0.5819\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7342 - loss: 0.5666 - val_accuracy: 0.7551 - val_loss: 0.5723\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7076 - loss: 0.5746 - val_accuracy: 0.7755 - val_loss: 0.5618\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7233 - loss: 0.5615 - val_accuracy: 0.7755 - val_loss: 0.5491\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7513 - loss: 0.5386 - val_accuracy: 0.7755 - val_loss: 0.5375\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7651 - loss: 0.5214 - val_accuracy: 0.7959 - val_loss: 0.5294\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7364 - loss: 0.5415 - val_accuracy: 0.7959 - val_loss: 0.5229\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7534 - loss: 0.5157 - val_accuracy: 0.7959 - val_loss: 0.5157\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7249 - loss: 0.5207 - val_accuracy: 0.7959 - val_loss: 0.5098\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7661 - loss: 0.4951 - val_accuracy: 0.7959 - val_loss: 0.5020\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7633 - loss: 0.4969 - val_accuracy: 0.7959 - val_loss: 0.4932\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7636 - loss: 0.4783 - val_accuracy: 0.7959 - val_loss: 0.4842\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.4643 - val_accuracy: 0.7755 - val_loss: 0.4762\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7584 - loss: 0.4752 - val_accuracy: 0.7959 - val_loss: 0.4686\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7814 - loss: 0.4529 - val_accuracy: 0.7959 - val_loss: 0.4604\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7706 - loss: 0.4445 - val_accuracy: 0.7959 - val_loss: 0.4520\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7985 - loss: 0.4393 - val_accuracy: 0.8163 - val_loss: 0.4441\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7714 - loss: 0.4356 - val_accuracy: 0.8163 - val_loss: 0.4362\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.4178 - val_accuracy: 0.8163 - val_loss: 0.4296\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7795 - loss: 0.4331 - val_accuracy: 0.8163 - val_loss: 0.4239\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8002 - loss: 0.4035 - val_accuracy: 0.8163 - val_loss: 0.4171\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7785 - loss: 0.3929 - val_accuracy: 0.8163 - val_loss: 0.4104\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7885 - loss: 0.4125 - val_accuracy: 0.8163 - val_loss: 0.4035\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7893 - loss: 0.3979 - val_accuracy: 0.8367 - val_loss: 0.3972\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8067 - loss: 0.3921 - val_accuracy: 0.8571 - val_loss: 0.3912\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8029 - loss: 0.3944 - val_accuracy: 0.8571 - val_loss: 0.3850\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7859 - loss: 0.4022 - val_accuracy: 0.8571 - val_loss: 0.3777\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7952 - loss: 0.4126 - val_accuracy: 0.8571 - val_loss: 0.3733\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Resultados con menos neuronas (8, 4):\n",
      "Accuracy: 0.7704918032786885\n",
      "Precision: 0.6\n",
      "Recall: 0.5294117647058824\n",
      "F1 Score: 0.5625\n"
     ]
    }
   ],
   "source": [
    "model_fewer_neurons = Sequential()\n",
    "model_fewer_neurons.add(Dense(8, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_fewer_neurons.add(Dense(4, activation='relu'))\n",
    "model_fewer_neurons.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_fewer_neurons.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_fewer_neurons = model_fewer_neurons.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_fewer_neurons = model_fewer_neurons.predict(X_test)\n",
    "y_pred_classes_fewer_neurons = (y_pred_fewer_neurons > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con menos neuronas (8, 4):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_fewer_neurons)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_fewer_neurons)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_fewer_neurons)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_fewer_neurons)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Con más neuronas: 32 y 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.5072 - loss: 0.7150 - val_accuracy: 0.5918 - val_loss: 0.6791\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6976 - loss: 0.6550 - val_accuracy: 0.6735 - val_loss: 0.6454\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7088 - loss: 0.6280 - val_accuracy: 0.7347 - val_loss: 0.6156\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7428 - loss: 0.5947 - val_accuracy: 0.7551 - val_loss: 0.5908\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7393 - loss: 0.5822 - val_accuracy: 0.7755 - val_loss: 0.5712\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7707 - loss: 0.5437 - val_accuracy: 0.7755 - val_loss: 0.5510\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7569 - loss: 0.5327 - val_accuracy: 0.7755 - val_loss: 0.5293\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7810 - loss: 0.5174 - val_accuracy: 0.8163 - val_loss: 0.5072\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7813 - loss: 0.5030 - val_accuracy: 0.8367 - val_loss: 0.4849\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8045 - loss: 0.4742 - val_accuracy: 0.8367 - val_loss: 0.4617\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8580 - loss: 0.4328 - val_accuracy: 0.8571 - val_loss: 0.4405\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8420 - loss: 0.4327 - val_accuracy: 0.8776 - val_loss: 0.4211\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8180 - loss: 0.4273 - val_accuracy: 0.8776 - val_loss: 0.4026\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8121 - loss: 0.4216 - val_accuracy: 0.8776 - val_loss: 0.3855\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7968 - loss: 0.4090 - val_accuracy: 0.8776 - val_loss: 0.3721\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8473 - loss: 0.3644 - val_accuracy: 0.8571 - val_loss: 0.3675\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8354 - loss: 0.3629 - val_accuracy: 0.8571 - val_loss: 0.3600\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8162 - loss: 0.3711 - val_accuracy: 0.8571 - val_loss: 0.3515\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8139 - loss: 0.3642 - val_accuracy: 0.8571 - val_loss: 0.3425\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8445 - loss: 0.3242 - val_accuracy: 0.8776 - val_loss: 0.3310\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8589 - loss: 0.3163 - val_accuracy: 0.9184 - val_loss: 0.3205\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8538 - loss: 0.3090 - val_accuracy: 0.9184 - val_loss: 0.3132\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8617 - loss: 0.3060 - val_accuracy: 0.8776 - val_loss: 0.3165\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8655 - loss: 0.2813 - val_accuracy: 0.8776 - val_loss: 0.3144\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8512 - loss: 0.3131 - val_accuracy: 0.8980 - val_loss: 0.3070\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8331 - loss: 0.3179 - val_accuracy: 0.8980 - val_loss: 0.2982\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8537 - loss: 0.3038 - val_accuracy: 0.8776 - val_loss: 0.2920\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8549 - loss: 0.3145 - val_accuracy: 0.8776 - val_loss: 0.2885\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8513 - loss: 0.3354 - val_accuracy: 0.8776 - val_loss: 0.2906\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8820 - loss: 0.2715 - val_accuracy: 0.8776 - val_loss: 0.2843\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8776 - loss: 0.2839 - val_accuracy: 0.8776 - val_loss: 0.2802\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8773 - loss: 0.2686 - val_accuracy: 0.8776 - val_loss: 0.2782\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8875 - loss: 0.2882 - val_accuracy: 0.8980 - val_loss: 0.2759\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8751 - loss: 0.3032 - val_accuracy: 0.8980 - val_loss: 0.2749\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9006 - loss: 0.2651 - val_accuracy: 0.8980 - val_loss: 0.2729\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8975 - loss: 0.2663 - val_accuracy: 0.8980 - val_loss: 0.2700\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8871 - loss: 0.2843 - val_accuracy: 0.8980 - val_loss: 0.2680\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8938 - loss: 0.2597 - val_accuracy: 0.8980 - val_loss: 0.2679\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8995 - loss: 0.2681 - val_accuracy: 0.8980 - val_loss: 0.2677\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9111 - loss: 0.2566 - val_accuracy: 0.8980 - val_loss: 0.2676\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8923 - loss: 0.2939 - val_accuracy: 0.8980 - val_loss: 0.2682\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9173 - loss: 0.2432 - val_accuracy: 0.8980 - val_loss: 0.2676\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9078 - loss: 0.2497 - val_accuracy: 0.8980 - val_loss: 0.2658\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9098 - loss: 0.2470 - val_accuracy: 0.8980 - val_loss: 0.2639\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8643 - loss: 0.2885 - val_accuracy: 0.9184 - val_loss: 0.2672\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8716 - loss: 0.2676 - val_accuracy: 0.8980 - val_loss: 0.2746\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8729 - loss: 0.2570 - val_accuracy: 0.8980 - val_loss: 0.2789\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8665 - loss: 0.2480 - val_accuracy: 0.8980 - val_loss: 0.2803\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8957 - loss: 0.2579 - val_accuracy: 0.8980 - val_loss: 0.2827\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2477 - val_accuracy: 0.8980 - val_loss: 0.2874\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
      "Resultados con más neuronas (32, 16):\n",
      "Accuracy: 0.8360655737704918\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model_more_neurons = Sequential()\n",
    "model_more_neurons.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_more_neurons.add(Dense(16, activation='relu'))\n",
    "model_more_neurons.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_more_neurons.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_more_neurons = model_more_neurons.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_more_neurons = model_more_neurons.predict(X_test)\n",
    "y_pred_classes_more_neurons = (y_pred_more_neurons > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con más neuronas (32, 16):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_more_neurons)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_more_neurons)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_more_neurons)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_more_neurons)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Con muchas más neuronas: 64 y 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.3357 - loss: 0.7880 - val_accuracy: 0.5918 - val_loss: 0.6824\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6720 - loss: 0.6445 - val_accuracy: 0.7755 - val_loss: 0.5959\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7646 - loss: 0.5674 - val_accuracy: 0.7755 - val_loss: 0.5396\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7132 - loss: 0.5305 - val_accuracy: 0.7755 - val_loss: 0.4983\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7432 - loss: 0.4910 - val_accuracy: 0.7755 - val_loss: 0.4556\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7715 - loss: 0.4459 - val_accuracy: 0.8163 - val_loss: 0.4183\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7942 - loss: 0.4067 - val_accuracy: 0.8367 - val_loss: 0.3845\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8593 - loss: 0.3675 - val_accuracy: 0.8980 - val_loss: 0.3563\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8735 - loss: 0.3662 - val_accuracy: 0.9388 - val_loss: 0.3325\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9248 - loss: 0.3183 - val_accuracy: 0.9184 - val_loss: 0.3139\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8735 - loss: 0.3288 - val_accuracy: 0.8980 - val_loss: 0.3093\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8846 - loss: 0.3144 - val_accuracy: 0.8980 - val_loss: 0.3030\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8557 - loss: 0.3181 - val_accuracy: 0.8980 - val_loss: 0.2912\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8677 - loss: 0.3138 - val_accuracy: 0.9388 - val_loss: 0.2803\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8489 - loss: 0.3059 - val_accuracy: 0.9184 - val_loss: 0.2760\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8511 - loss: 0.3404 - val_accuracy: 0.9184 - val_loss: 0.2733\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8703 - loss: 0.2907 - val_accuracy: 0.8980 - val_loss: 0.2713\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9031 - loss: 0.2599 - val_accuracy: 0.8980 - val_loss: 0.2721\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8870 - loss: 0.2684 - val_accuracy: 0.9184 - val_loss: 0.2784\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8894 - loss: 0.2513 - val_accuracy: 0.9184 - val_loss: 0.2796\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8893 - loss: 0.2634 - val_accuracy: 0.8980 - val_loss: 0.2748\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8850 - loss: 0.2517 - val_accuracy: 0.8980 - val_loss: 0.2730\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8845 - loss: 0.2538 - val_accuracy: 0.8980 - val_loss: 0.2756\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8955 - loss: 0.2564 - val_accuracy: 0.8980 - val_loss: 0.2782\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9083 - loss: 0.2278 - val_accuracy: 0.8980 - val_loss: 0.2779\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9111 - loss: 0.2501 - val_accuracy: 0.8980 - val_loss: 0.2756\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8991 - loss: 0.2421 - val_accuracy: 0.8980 - val_loss: 0.2754\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9013 - loss: 0.2381 - val_accuracy: 0.8980 - val_loss: 0.2780\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9021 - loss: 0.2476 - val_accuracy: 0.8980 - val_loss: 0.2771\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8885 - loss: 0.2549 - val_accuracy: 0.8980 - val_loss: 0.2790\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9212 - loss: 0.2189 - val_accuracy: 0.8776 - val_loss: 0.2862\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9150 - loss: 0.2244 - val_accuracy: 0.8776 - val_loss: 0.3062\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9222 - loss: 0.2052 - val_accuracy: 0.8776 - val_loss: 0.3120\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9298 - loss: 0.2186 - val_accuracy: 0.8776 - val_loss: 0.3130\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9132 - loss: 0.2349 - val_accuracy: 0.8776 - val_loss: 0.3136\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9216 - loss: 0.2273 - val_accuracy: 0.8776 - val_loss: 0.3135\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9203 - loss: 0.2130 - val_accuracy: 0.8776 - val_loss: 0.3150\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9194 - loss: 0.2174 - val_accuracy: 0.8776 - val_loss: 0.3068\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9342 - loss: 0.1869 - val_accuracy: 0.8776 - val_loss: 0.3069\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9426 - loss: 0.1817 - val_accuracy: 0.8776 - val_loss: 0.3145\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9206 - loss: 0.1990 - val_accuracy: 0.8776 - val_loss: 0.3181\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9506 - loss: 0.1713 - val_accuracy: 0.8776 - val_loss: 0.3199\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9217 - loss: 0.1900 - val_accuracy: 0.8776 - val_loss: 0.3148\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9341 - loss: 0.1818 - val_accuracy: 0.8571 - val_loss: 0.3058\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9195 - loss: 0.1989 - val_accuracy: 0.8571 - val_loss: 0.3042\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9352 - loss: 0.1827 - val_accuracy: 0.8776 - val_loss: 0.3020\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9345 - loss: 0.1692 - val_accuracy: 0.8776 - val_loss: 0.3050\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9413 - loss: 0.1636 - val_accuracy: 0.8776 - val_loss: 0.3087\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9425 - loss: 0.1606 - val_accuracy: 0.8980 - val_loss: 0.3120\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9408 - loss: 0.1524 - val_accuracy: 0.8776 - val_loss: 0.3193\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
      "Resultados con muchas más neuronas (64, 32):\n",
      "Accuracy: 0.819672131147541\n",
      "Precision: 0.6875\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "model_large_neurons = Sequential()\n",
    "model_large_neurons.add(Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_large_neurons.add(Dense(32, activation='relu'))\n",
    "model_large_neurons.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_large_neurons.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_large_neurons = model_large_neurons.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_large_neurons = model_large_neurons.predict(X_test)\n",
    "y_pred_classes_large_neurons = (y_pred_large_neurons > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con muchas más neuronas (64, 32):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_large_neurons)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_large_neurons)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_large_neurons)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_large_neurons)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Modifique el número de capas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con una sola capa oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.3011 - loss: 0.8619 - val_accuracy: 0.3061 - val_loss: 0.9489\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3135 - loss: 0.8250 - val_accuracy: 0.2857 - val_loss: 0.9045\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3313 - loss: 0.8205 - val_accuracy: 0.2857 - val_loss: 0.8685\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3713 - loss: 0.7730 - val_accuracy: 0.3265 - val_loss: 0.8401\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.3864 - loss: 0.7659 - val_accuracy: 0.3673 - val_loss: 0.8173\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4059 - loss: 0.7483 - val_accuracy: 0.3878 - val_loss: 0.7966\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.4790 - loss: 0.7121 - val_accuracy: 0.4286 - val_loss: 0.7785\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5171 - loss: 0.6943 - val_accuracy: 0.4490 - val_loss: 0.7624\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5405 - loss: 0.6943 - val_accuracy: 0.4898 - val_loss: 0.7451\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6470 - loss: 0.6477 - val_accuracy: 0.5102 - val_loss: 0.7304\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6536 - loss: 0.6604 - val_accuracy: 0.5714 - val_loss: 0.7165\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6825 - loss: 0.6379 - val_accuracy: 0.6122 - val_loss: 0.7039\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7005 - loss: 0.6323 - val_accuracy: 0.6122 - val_loss: 0.6925\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7338 - loss: 0.6251 - val_accuracy: 0.6122 - val_loss: 0.6822\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7702 - loss: 0.6077 - val_accuracy: 0.6122 - val_loss: 0.6705\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7610 - loss: 0.5999 - val_accuracy: 0.6531 - val_loss: 0.6589\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7988 - loss: 0.5992 - val_accuracy: 0.6939 - val_loss: 0.6475\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7764 - loss: 0.5844 - val_accuracy: 0.6939 - val_loss: 0.6363\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7968 - loss: 0.5713 - val_accuracy: 0.7143 - val_loss: 0.6257\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7643 - loss: 0.5707 - val_accuracy: 0.6939 - val_loss: 0.6135\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.5519 - val_accuracy: 0.7347 - val_loss: 0.6017\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8371 - loss: 0.5319 - val_accuracy: 0.7143 - val_loss: 0.5894\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8279 - loss: 0.5362 - val_accuracy: 0.7143 - val_loss: 0.5765\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8174 - loss: 0.5324 - val_accuracy: 0.7347 - val_loss: 0.5659\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8455 - loss: 0.5041 - val_accuracy: 0.7347 - val_loss: 0.5568\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8541 - loss: 0.5049 - val_accuracy: 0.7347 - val_loss: 0.5495\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8392 - loss: 0.5043 - val_accuracy: 0.7551 - val_loss: 0.5416\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8326 - loss: 0.4996 - val_accuracy: 0.7551 - val_loss: 0.5337\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.4915 - val_accuracy: 0.7755 - val_loss: 0.5247\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8393 - loss: 0.4833 - val_accuracy: 0.7755 - val_loss: 0.5157\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8245 - loss: 0.4667 - val_accuracy: 0.7755 - val_loss: 0.5055\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8572 - loss: 0.4538 - val_accuracy: 0.7755 - val_loss: 0.4959\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8361 - loss: 0.4580 - val_accuracy: 0.7551 - val_loss: 0.4865\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8454 - loss: 0.4352 - val_accuracy: 0.7551 - val_loss: 0.4761\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8451 - loss: 0.4402 - val_accuracy: 0.7755 - val_loss: 0.4660\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8478 - loss: 0.4247 - val_accuracy: 0.7755 - val_loss: 0.4564\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8464 - loss: 0.4198 - val_accuracy: 0.7755 - val_loss: 0.4478\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8387 - loss: 0.4197 - val_accuracy: 0.7755 - val_loss: 0.4393\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8690 - loss: 0.3937 - val_accuracy: 0.7959 - val_loss: 0.4305\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8613 - loss: 0.3783 - val_accuracy: 0.7959 - val_loss: 0.4225\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8436 - loss: 0.3856 - val_accuracy: 0.8163 - val_loss: 0.4147\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8673 - loss: 0.3732 - val_accuracy: 0.8163 - val_loss: 0.4078\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8296 - loss: 0.4081 - val_accuracy: 0.8163 - val_loss: 0.4012\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8757 - loss: 0.3626 - val_accuracy: 0.8163 - val_loss: 0.3946\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8649 - loss: 0.3567 - val_accuracy: 0.8367 - val_loss: 0.3876\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8511 - loss: 0.3798 - val_accuracy: 0.8367 - val_loss: 0.3819\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8548 - loss: 0.3731 - val_accuracy: 0.8367 - val_loss: 0.3764\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8292 - loss: 0.3749 - val_accuracy: 0.8367 - val_loss: 0.3710\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8499 - loss: 0.3580 - val_accuracy: 0.8367 - val_loss: 0.3660\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8683 - loss: 0.3310 - val_accuracy: 0.8367 - val_loss: 0.3619\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Resultados con una sola capa (16 neuronas):\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.8333333333333334\n",
      "Recall: 0.5882352941176471\n",
      "F1 Score: 0.6896551724137931\n"
     ]
    }
   ],
   "source": [
    "model_one_layer = Sequential()\n",
    "model_one_layer.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_one_layer.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model_one_layer.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_one_layer = model_one_layer.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_one_layer = model_one_layer.predict(X_test)\n",
    "y_pred_classes_one_layer = (y_pred_one_layer > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con una sola capa (16 neuronas):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_one_layer)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_one_layer)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_one_layer)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_one_layer)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con tres capas ocultas: 16, 8, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.6798 - loss: 0.6254 - val_accuracy: 0.7959 - val_loss: 0.5916\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6963 - loss: 0.5992 - val_accuracy: 0.7755 - val_loss: 0.5708\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7304 - loss: 0.5679 - val_accuracy: 0.7755 - val_loss: 0.5514\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7231 - loss: 0.5621 - val_accuracy: 0.7551 - val_loss: 0.5324\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7278 - loss: 0.5339 - val_accuracy: 0.7551 - val_loss: 0.5142\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7420 - loss: 0.5133 - val_accuracy: 0.7551 - val_loss: 0.4967\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7666 - loss: 0.4828 - val_accuracy: 0.7551 - val_loss: 0.4801\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7455 - loss: 0.4671 - val_accuracy: 0.7551 - val_loss: 0.4648\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6992 - loss: 0.4965 - val_accuracy: 0.7755 - val_loss: 0.4505\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7276 - loss: 0.4579 - val_accuracy: 0.7959 - val_loss: 0.4364\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7448 - loss: 0.4515 - val_accuracy: 0.8163 - val_loss: 0.4240\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7708 - loss: 0.4503 - val_accuracy: 0.8163 - val_loss: 0.4133\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8119 - loss: 0.3988 - val_accuracy: 0.8571 - val_loss: 0.4024\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7984 - loss: 0.4017 - val_accuracy: 0.8776 - val_loss: 0.3917\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8388 - loss: 0.3818 - val_accuracy: 0.8571 - val_loss: 0.3835\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8270 - loss: 0.3731 - val_accuracy: 0.8571 - val_loss: 0.3750\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8448 - loss: 0.3531 - val_accuracy: 0.8571 - val_loss: 0.3670\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8203 - loss: 0.3706 - val_accuracy: 0.8571 - val_loss: 0.3600\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7966 - loss: 0.3948 - val_accuracy: 0.8571 - val_loss: 0.3531\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8440 - loss: 0.3401 - val_accuracy: 0.8571 - val_loss: 0.3474\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8281 - loss: 0.3556 - val_accuracy: 0.8571 - val_loss: 0.3425\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8429 - loss: 0.3353 - val_accuracy: 0.8571 - val_loss: 0.3367\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8285 - loss: 0.3634 - val_accuracy: 0.8367 - val_loss: 0.3296\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8438 - loss: 0.3265 - val_accuracy: 0.8367 - val_loss: 0.3207\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8589 - loss: 0.3106 - val_accuracy: 0.8367 - val_loss: 0.3161\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8514 - loss: 0.3087 - val_accuracy: 0.8367 - val_loss: 0.3137\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8734 - loss: 0.2855 - val_accuracy: 0.8776 - val_loss: 0.3095\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8382 - loss: 0.3203 - val_accuracy: 0.8776 - val_loss: 0.3044\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8814 - loss: 0.2832 - val_accuracy: 0.8776 - val_loss: 0.3004\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8644 - loss: 0.2876 - val_accuracy: 0.8776 - val_loss: 0.2972\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8441 - loss: 0.3234 - val_accuracy: 0.8571 - val_loss: 0.2982\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8766 - loss: 0.2754 - val_accuracy: 0.8776 - val_loss: 0.2923\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8230 - loss: 0.3105 - val_accuracy: 0.8776 - val_loss: 0.2863\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8657 - loss: 0.3098 - val_accuracy: 0.8776 - val_loss: 0.2834\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8724 - loss: 0.2928 - val_accuracy: 0.8776 - val_loss: 0.2816\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8603 - loss: 0.2834 - val_accuracy: 0.8980 - val_loss: 0.2809\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8814 - loss: 0.2585 - val_accuracy: 0.8980 - val_loss: 0.2818\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8618 - loss: 0.2812 - val_accuracy: 0.8571 - val_loss: 0.2832\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8808 - loss: 0.2511 - val_accuracy: 0.8571 - val_loss: 0.2844\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8818 - loss: 0.2610 - val_accuracy: 0.8571 - val_loss: 0.2876\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8571 - loss: 0.2795 - val_accuracy: 0.8571 - val_loss: 0.2884\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8763 - loss: 0.2818 - val_accuracy: 0.8571 - val_loss: 0.2928\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8830 - loss: 0.2647 - val_accuracy: 0.8571 - val_loss: 0.2971\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8793 - loss: 0.2631 - val_accuracy: 0.8776 - val_loss: 0.2977\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8588 - loss: 0.2877 - val_accuracy: 0.8571 - val_loss: 0.2947\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8871 - loss: 0.2614 - val_accuracy: 0.8571 - val_loss: 0.2924\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8664 - loss: 0.2872 - val_accuracy: 0.8776 - val_loss: 0.2895\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8643 - loss: 0.2832 - val_accuracy: 0.8571 - val_loss: 0.2902\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8734 - loss: 0.2710 - val_accuracy: 0.8571 - val_loss: 0.2998\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8810 - loss: 0.2608 - val_accuracy: 0.8571 - val_loss: 0.3007\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n",
      "Resultados con tres capas ocultas (16, 8, 4 neuronas):\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.75\n",
      "Recall: 0.7058823529411765\n",
      "F1 Score: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "model_three_layers = Sequential()\n",
    "model_three_layers.add(Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_three_layers.add(Dense(8, activation='relu'))\n",
    "model_three_layers.add(Dense(4, activation='relu'))\n",
    "model_three_layers.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_three_layers.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_three_layers = model_three_layers.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_three_layers = model_three_layers.predict(X_test)\n",
    "y_pred_classes_three_layers = (y_pred_three_layers > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con tres capas ocultas (16, 8, 4 neuronas):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_three_layers)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_three_layers)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_three_layers)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_three_layers)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo con cuatro capas ocultas: 32, 16, 8, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.4006 - loss: 0.6948 - val_accuracy: 0.4286 - val_loss: 0.6970\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5485 - loss: 0.6709 - val_accuracy: 0.6735 - val_loss: 0.6732\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7319 - loss: 0.6414 - val_accuracy: 0.7551 - val_loss: 0.6371\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7138 - loss: 0.6190 - val_accuracy: 0.7551 - val_loss: 0.5943\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7276 - loss: 0.5706 - val_accuracy: 0.7551 - val_loss: 0.5483\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7409 - loss: 0.5281 - val_accuracy: 0.7551 - val_loss: 0.5053\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7099 - loss: 0.5024 - val_accuracy: 0.7551 - val_loss: 0.4677\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7214 - loss: 0.4612 - val_accuracy: 0.7551 - val_loss: 0.4347\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7062 - loss: 0.4560 - val_accuracy: 0.7551 - val_loss: 0.4075\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7188 - loss: 0.4355 - val_accuracy: 0.7551 - val_loss: 0.3862\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7209 - loss: 0.4043 - val_accuracy: 0.7755 - val_loss: 0.3679\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7364 - loss: 0.3973 - val_accuracy: 0.7755 - val_loss: 0.3574\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7329 - loss: 0.3665 - val_accuracy: 0.7959 - val_loss: 0.3487\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7346 - loss: 0.3949 - val_accuracy: 0.7959 - val_loss: 0.3401\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7724 - loss: 0.3527 - val_accuracy: 0.7959 - val_loss: 0.3325\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7756 - loss: 0.3768 - val_accuracy: 0.7959 - val_loss: 0.3296\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8532 - loss: 0.3286 - val_accuracy: 0.7959 - val_loss: 0.3293\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8686 - loss: 0.3380 - val_accuracy: 0.8163 - val_loss: 0.3248\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8970 - loss: 0.2992 - val_accuracy: 0.8163 - val_loss: 0.3171\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8677 - loss: 0.3204 - val_accuracy: 0.7959 - val_loss: 0.3110\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8870 - loss: 0.3067 - val_accuracy: 0.8367 - val_loss: 0.3077\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8592 - loss: 0.3021 - val_accuracy: 0.8571 - val_loss: 0.3043\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8853 - loss: 0.2921 - val_accuracy: 0.8776 - val_loss: 0.3006\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8842 - loss: 0.2896 - val_accuracy: 0.8980 - val_loss: 0.2967\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8820 - loss: 0.3314 - val_accuracy: 0.8776 - val_loss: 0.2925\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8822 - loss: 0.2684 - val_accuracy: 0.8776 - val_loss: 0.2932\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8639 - loss: 0.3033 - val_accuracy: 0.8571 - val_loss: 0.2990\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8622 - loss: 0.2975 - val_accuracy: 0.8571 - val_loss: 0.2957\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8884 - loss: 0.2825 - val_accuracy: 0.8776 - val_loss: 0.2871\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8915 - loss: 0.2794 - val_accuracy: 0.8776 - val_loss: 0.2818\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9093 - loss: 0.2697 - val_accuracy: 0.8776 - val_loss: 0.2788\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9061 - loss: 0.2626 - val_accuracy: 0.8776 - val_loss: 0.2771\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8885 - loss: 0.2564 - val_accuracy: 0.8776 - val_loss: 0.2763\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9215 - loss: 0.2294 - val_accuracy: 0.8776 - val_loss: 0.2738\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9050 - loss: 0.2547 - val_accuracy: 0.8776 - val_loss: 0.2734\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8805 - loss: 0.2472 - val_accuracy: 0.8776 - val_loss: 0.2716\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9002 - loss: 0.2416 - val_accuracy: 0.8776 - val_loss: 0.2718\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8897 - loss: 0.2711 - val_accuracy: 0.8776 - val_loss: 0.2749\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8931 - loss: 0.2449 - val_accuracy: 0.8776 - val_loss: 0.2715\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9055 - loss: 0.2378 - val_accuracy: 0.8776 - val_loss: 0.2683\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9299 - loss: 0.2123 - val_accuracy: 0.8776 - val_loss: 0.2659\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9268 - loss: 0.2301 - val_accuracy: 0.8776 - val_loss: 0.2622\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9093 - loss: 0.2197 - val_accuracy: 0.8776 - val_loss: 0.2629\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8993 - loss: 0.2554 - val_accuracy: 0.8776 - val_loss: 0.2621\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9302 - loss: 0.2069 - val_accuracy: 0.8776 - val_loss: 0.2624\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9081 - loss: 0.2266 - val_accuracy: 0.8776 - val_loss: 0.2635\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9224 - loss: 0.2248 - val_accuracy: 0.8776 - val_loss: 0.2634\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9232 - loss: 0.2115 - val_accuracy: 0.8776 - val_loss: 0.2641\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9446 - loss: 0.1843 - val_accuracy: 0.8776 - val_loss: 0.2655\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9273 - loss: 0.1925 - val_accuracy: 0.8776 - val_loss: 0.2762\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Resultados con cuatro capas ocultas (32, 16, 8, 4 neuronas):\n",
      "Accuracy: 0.8360655737704918\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model_four_layers = Sequential()\n",
    "model_four_layers.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model_four_layers.add(Dense(16, activation='relu'))\n",
    "model_four_layers.add(Dense(8, activation='relu')) \n",
    "model_four_layers.add(Dense(4, activation='relu'))\n",
    "model_four_layers.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model_four_layers.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_four_layers = model_four_layers.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_four_layers = model_four_layers.predict(X_test)\n",
    "y_pred_classes_four_layers = (y_pred_four_layers > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con cuatro capas ocultas (32, 16, 8, 4 neuronas):')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_four_layers)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_four_layers)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_four_layers)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_four_layers)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Modifique las funciones de activación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Función de activación Tanh en las capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.4149 - loss: 0.7943 - val_accuracy: 0.4694 - val_loss: 0.7568\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5200 - loss: 0.6925 - val_accuracy: 0.5918 - val_loss: 0.6864\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5973 - loss: 0.6688 - val_accuracy: 0.6735 - val_loss: 0.6324\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6769 - loss: 0.6180 - val_accuracy: 0.7143 - val_loss: 0.5915\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7477 - loss: 0.5651 - val_accuracy: 0.7551 - val_loss: 0.5598\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7479 - loss: 0.5592 - val_accuracy: 0.7959 - val_loss: 0.5416\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7372 - loss: 0.5368 - val_accuracy: 0.7959 - val_loss: 0.5295\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7787 - loss: 0.5272 - val_accuracy: 0.7959 - val_loss: 0.5163\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7703 - loss: 0.5126 - val_accuracy: 0.7959 - val_loss: 0.4990\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7755 - loss: 0.5247 - val_accuracy: 0.7959 - val_loss: 0.4822\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7919 - loss: 0.4781 - val_accuracy: 0.7755 - val_loss: 0.4669\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7882 - loss: 0.4647 - val_accuracy: 0.7755 - val_loss: 0.4526\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8049 - loss: 0.4524 - val_accuracy: 0.7755 - val_loss: 0.4397\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7928 - loss: 0.4602 - val_accuracy: 0.7959 - val_loss: 0.4278\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8129 - loss: 0.4239 - val_accuracy: 0.7959 - val_loss: 0.4172\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8196 - loss: 0.4056 - val_accuracy: 0.7959 - val_loss: 0.4078\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8210 - loss: 0.3961 - val_accuracy: 0.7959 - val_loss: 0.3994\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8280 - loss: 0.3968 - val_accuracy: 0.7959 - val_loss: 0.3915\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8106 - loss: 0.4151 - val_accuracy: 0.7959 - val_loss: 0.3814\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8381 - loss: 0.3791 - val_accuracy: 0.7959 - val_loss: 0.3735\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8421 - loss: 0.3730 - val_accuracy: 0.8163 - val_loss: 0.3702\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8309 - loss: 0.3857 - val_accuracy: 0.8163 - val_loss: 0.3662\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8421 - loss: 0.3663 - val_accuracy: 0.8163 - val_loss: 0.3602\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8247 - loss: 0.3755 - val_accuracy: 0.8163 - val_loss: 0.3525\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8469 - loss: 0.3713 - val_accuracy: 0.8163 - val_loss: 0.3459\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8408 - loss: 0.3578 - val_accuracy: 0.8367 - val_loss: 0.3419\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8134 - loss: 0.3642 - val_accuracy: 0.8367 - val_loss: 0.3375\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8431 - loss: 0.3417 - val_accuracy: 0.8367 - val_loss: 0.3328\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8384 - loss: 0.3497 - val_accuracy: 0.8163 - val_loss: 0.3261\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8405 - loss: 0.3582 - val_accuracy: 0.8163 - val_loss: 0.3207\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8509 - loss: 0.3493 - val_accuracy: 0.8163 - val_loss: 0.3179\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8452 - loss: 0.3454 - val_accuracy: 0.8163 - val_loss: 0.3150\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8646 - loss: 0.3354 - val_accuracy: 0.8367 - val_loss: 0.3124\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8724 - loss: 0.3145 - val_accuracy: 0.8367 - val_loss: 0.3098\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8543 - loss: 0.3393 - val_accuracy: 0.8367 - val_loss: 0.3082\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8861 - loss: 0.3115 - val_accuracy: 0.8367 - val_loss: 0.3108\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8711 - loss: 0.3364 - val_accuracy: 0.8367 - val_loss: 0.3104\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8731 - loss: 0.3135 - val_accuracy: 0.8367 - val_loss: 0.3086\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8463 - loss: 0.3355 - val_accuracy: 0.8367 - val_loss: 0.3059\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8936 - loss: 0.3164 - val_accuracy: 0.8367 - val_loss: 0.3026\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8573 - loss: 0.3350 - val_accuracy: 0.8571 - val_loss: 0.2965\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8383 - loss: 0.3373 - val_accuracy: 0.8980 - val_loss: 0.2913\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8657 - loss: 0.3172 - val_accuracy: 0.8980 - val_loss: 0.2849\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8573 - loss: 0.3282 - val_accuracy: 0.8980 - val_loss: 0.2813\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8713 - loss: 0.3054 - val_accuracy: 0.8776 - val_loss: 0.2791\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8683 - loss: 0.3112 - val_accuracy: 0.8776 - val_loss: 0.2805\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8696 - loss: 0.2954 - val_accuracy: 0.8776 - val_loss: 0.2810\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8585 - loss: 0.3179 - val_accuracy: 0.8776 - val_loss: 0.2814\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8561 - loss: 0.3125 - val_accuracy: 0.8776 - val_loss: 0.2814\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8670 - loss: 0.2991 - val_accuracy: 0.8776 - val_loss: 0.2811\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step\n",
      "Resultados con función Tanh:\n",
      "Accuracy: 0.8524590163934426\n",
      "Precision: 0.75\n",
      "Recall: 0.7058823529411765\n",
      "F1 Score: 0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "model_tanh = Sequential()\n",
    "model_tanh.add(Dense(16, activation='tanh', input_shape=(X_train.shape[1],)))\n",
    "model_tanh.add(Dense(8, activation='tanh'))\n",
    "model_tanh.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_tanh.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_tanh = model_tanh.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_tanh = model_tanh.predict(X_test)\n",
    "y_pred_classes_tanh = (y_pred_tanh > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con función Tanh:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_tanh)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_tanh)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_tanh)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_tanh)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Función de activación Sigmoid en las capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.2536 - loss: 0.7364 - val_accuracy: 0.3673 - val_loss: 0.7044\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3799 - loss: 0.7042 - val_accuracy: 0.7551 - val_loss: 0.6725\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6186 - loss: 0.6814 - val_accuracy: 0.7755 - val_loss: 0.6445\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7133 - loss: 0.6561 - val_accuracy: 0.7551 - val_loss: 0.6205\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7073 - loss: 0.6411 - val_accuracy: 0.7551 - val_loss: 0.6000\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7206 - loss: 0.6215 - val_accuracy: 0.7551 - val_loss: 0.5837\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6726 - loss: 0.6248 - val_accuracy: 0.7551 - val_loss: 0.5734\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6970 - loss: 0.6112 - val_accuracy: 0.7551 - val_loss: 0.5625\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7306 - loss: 0.5829 - val_accuracy: 0.7551 - val_loss: 0.5521\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7244 - loss: 0.5787 - val_accuracy: 0.7551 - val_loss: 0.5434\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7124 - loss: 0.5831 - val_accuracy: 0.7551 - val_loss: 0.5368\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7461 - loss: 0.5569 - val_accuracy: 0.7551 - val_loss: 0.5322\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6855 - loss: 0.5952 - val_accuracy: 0.7551 - val_loss: 0.5279\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7006 - loss: 0.5796 - val_accuracy: 0.7551 - val_loss: 0.5254\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7068 - loss: 0.5733 - val_accuracy: 0.7551 - val_loss: 0.5230\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7142 - loss: 0.5642 - val_accuracy: 0.7551 - val_loss: 0.5190\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7133 - loss: 0.5617 - val_accuracy: 0.7551 - val_loss: 0.5145\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7159 - loss: 0.5622 - val_accuracy: 0.7551 - val_loss: 0.5101\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7324 - loss: 0.5359 - val_accuracy: 0.7551 - val_loss: 0.5060\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7334 - loss: 0.5366 - val_accuracy: 0.7551 - val_loss: 0.5033\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7154 - loss: 0.5466 - val_accuracy: 0.7551 - val_loss: 0.5001\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7311 - loss: 0.5352 - val_accuracy: 0.7551 - val_loss: 0.4967\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7140 - loss: 0.5490 - val_accuracy: 0.7551 - val_loss: 0.4934\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7090 - loss: 0.5421 - val_accuracy: 0.7551 - val_loss: 0.4908\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7340 - loss: 0.5218 - val_accuracy: 0.7551 - val_loss: 0.4878\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7125 - loss: 0.5304 - val_accuracy: 0.7551 - val_loss: 0.4850\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7457 - loss: 0.5059 - val_accuracy: 0.7551 - val_loss: 0.4820\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7439 - loss: 0.5062 - val_accuracy: 0.7551 - val_loss: 0.4788\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7498 - loss: 0.5024 - val_accuracy: 0.7551 - val_loss: 0.4756\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7381 - loss: 0.5001 - val_accuracy: 0.7551 - val_loss: 0.4722\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7137 - loss: 0.5211 - val_accuracy: 0.7551 - val_loss: 0.4690\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7111 - loss: 0.5265 - val_accuracy: 0.7551 - val_loss: 0.4659\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7157 - loss: 0.5214 - val_accuracy: 0.7551 - val_loss: 0.4638\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7024 - loss: 0.5242 - val_accuracy: 0.7551 - val_loss: 0.4619\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7254 - loss: 0.5021 - val_accuracy: 0.7551 - val_loss: 0.4595\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7279 - loss: 0.5003 - val_accuracy: 0.7551 - val_loss: 0.4571\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6899 - loss: 0.5282 - val_accuracy: 0.7551 - val_loss: 0.4544\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7132 - loss: 0.5028 - val_accuracy: 0.7551 - val_loss: 0.4516\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7497 - loss: 0.4755 - val_accuracy: 0.7551 - val_loss: 0.4487\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7428 - loss: 0.4886 - val_accuracy: 0.7551 - val_loss: 0.4459\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 486ms/step - accuracy: 0.7024 - loss: 0.5049 - val_accuracy: 0.7551 - val_loss: 0.4428\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7225 - loss: 0.4853 - val_accuracy: 0.7551 - val_loss: 0.4393\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7045 - loss: 0.4939 - val_accuracy: 0.7551 - val_loss: 0.4353\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7450 - loss: 0.4597 - val_accuracy: 0.7551 - val_loss: 0.4315\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7229 - loss: 0.4751 - val_accuracy: 0.7551 - val_loss: 0.4273\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7152 - loss: 0.4769 - val_accuracy: 0.7755 - val_loss: 0.4231\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7140 - loss: 0.4831 - val_accuracy: 0.7755 - val_loss: 0.4194\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7294 - loss: 0.4585 - val_accuracy: 0.7755 - val_loss: 0.4166\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7127 - loss: 0.4708 - val_accuracy: 0.7755 - val_loss: 0.4134\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7417 - loss: 0.4383 - val_accuracy: 0.7755 - val_loss: 0.4100\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Resultados con función Sigmoid:\n",
      "Accuracy: 0.7540983606557377\n",
      "Precision: 0.75\n",
      "Recall: 0.17647058823529413\n",
      "F1 Score: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "model_sigmoid = Sequential()\n",
    "model_sigmoid.add(Dense(16, activation='sigmoid', input_shape=(X_train.shape[1],)))\n",
    "model_sigmoid.add(Dense(8, activation='sigmoid'))\n",
    "model_sigmoid.add(Dense(1, activation='sigmoid'))  \n",
    "\n",
    "model_sigmoid.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_sigmoid = model_sigmoid.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_sigmoid = model_sigmoid.predict(X_test)\n",
    "y_pred_classes_sigmoid = (y_pred_sigmoid > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con función Sigmoid:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_sigmoid)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_sigmoid)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_sigmoid)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_sigmoid)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 3: Función de activación Leaky ReLU en las capas ocultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/layers/activations/leaky_relu.py:41: UserWarning: Argument `alpha` is deprecated. Use `negative_slope` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.3743 - loss: 0.7653 - val_accuracy: 0.3878 - val_loss: 0.7314\n",
      "Epoch 2/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.4641 - loss: 0.7267 - val_accuracy: 0.5510 - val_loss: 0.7067\n",
      "Epoch 3/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4911 - loss: 0.7133 - val_accuracy: 0.5918 - val_loss: 0.6906\n",
      "Epoch 4/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6359 - loss: 0.6934 - val_accuracy: 0.6327 - val_loss: 0.6777\n",
      "Epoch 5/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6702 - loss: 0.6856 - val_accuracy: 0.7755 - val_loss: 0.6692\n",
      "Epoch 6/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.6944 - loss: 0.6762 - val_accuracy: 0.7959 - val_loss: 0.6602\n",
      "Epoch 7/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7804 - loss: 0.6653 - val_accuracy: 0.8163 - val_loss: 0.6515\n",
      "Epoch 8/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8056 - loss: 0.6528 - val_accuracy: 0.8163 - val_loss: 0.6435\n",
      "Epoch 9/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7928 - loss: 0.6458 - val_accuracy: 0.8367 - val_loss: 0.6354\n",
      "Epoch 10/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8178 - loss: 0.6372 - val_accuracy: 0.8367 - val_loss: 0.6271\n",
      "Epoch 11/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7838 - loss: 0.6347 - val_accuracy: 0.8367 - val_loss: 0.6177\n",
      "Epoch 12/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8359 - loss: 0.6199 - val_accuracy: 0.8571 - val_loss: 0.6067\n",
      "Epoch 13/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8296 - loss: 0.6097 - val_accuracy: 0.8571 - val_loss: 0.5952\n",
      "Epoch 14/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7954 - loss: 0.6087 - val_accuracy: 0.8571 - val_loss: 0.5834\n",
      "Epoch 15/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8053 - loss: 0.5969 - val_accuracy: 0.8571 - val_loss: 0.5702\n",
      "Epoch 16/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8182 - loss: 0.5853 - val_accuracy: 0.8776 - val_loss: 0.5553\n",
      "Epoch 17/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7820 - loss: 0.5714 - val_accuracy: 0.8571 - val_loss: 0.5383\n",
      "Epoch 18/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8077 - loss: 0.5493 - val_accuracy: 0.8571 - val_loss: 0.5201\n",
      "Epoch 19/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8135 - loss: 0.5361 - val_accuracy: 0.8571 - val_loss: 0.5026\n",
      "Epoch 20/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8194 - loss: 0.5157 - val_accuracy: 0.8571 - val_loss: 0.4874\n",
      "Epoch 21/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8213 - loss: 0.5012 - val_accuracy: 0.8571 - val_loss: 0.4715\n",
      "Epoch 22/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8259 - loss: 0.4969 - val_accuracy: 0.8571 - val_loss: 0.4564\n",
      "Epoch 23/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7979 - loss: 0.4899 - val_accuracy: 0.8367 - val_loss: 0.4468\n",
      "Epoch 24/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8144 - loss: 0.4767 - val_accuracy: 0.8367 - val_loss: 0.4360\n",
      "Epoch 25/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7868 - loss: 0.4721 - val_accuracy: 0.8367 - val_loss: 0.4255\n",
      "Epoch 26/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8151 - loss: 0.4476 - val_accuracy: 0.8367 - val_loss: 0.4144\n",
      "Epoch 27/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8047 - loss: 0.4484 - val_accuracy: 0.8367 - val_loss: 0.4042\n",
      "Epoch 28/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8063 - loss: 0.4334 - val_accuracy: 0.8367 - val_loss: 0.3941\n",
      "Epoch 29/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7880 - loss: 0.4365 - val_accuracy: 0.8367 - val_loss: 0.3845\n",
      "Epoch 30/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7822 - loss: 0.4444 - val_accuracy: 0.8367 - val_loss: 0.3762\n",
      "Epoch 31/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7861 - loss: 0.4229 - val_accuracy: 0.8367 - val_loss: 0.3690\n",
      "Epoch 32/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8342 - loss: 0.3938 - val_accuracy: 0.8367 - val_loss: 0.3618\n",
      "Epoch 33/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7998 - loss: 0.3982 - val_accuracy: 0.8367 - val_loss: 0.3554\n",
      "Epoch 34/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8365 - loss: 0.3654 - val_accuracy: 0.8367 - val_loss: 0.3489\n",
      "Epoch 35/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8109 - loss: 0.3754 - val_accuracy: 0.8367 - val_loss: 0.3433\n",
      "Epoch 36/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8204 - loss: 0.3675 - val_accuracy: 0.8367 - val_loss: 0.3373\n",
      "Epoch 37/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7957 - loss: 0.3793 - val_accuracy: 0.8571 - val_loss: 0.3286\n",
      "Epoch 38/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8343 - loss: 0.3618 - val_accuracy: 0.8980 - val_loss: 0.3219\n",
      "Epoch 39/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8046 - loss: 0.3923 - val_accuracy: 0.8980 - val_loss: 0.3177\n",
      "Epoch 40/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7969 - loss: 0.3859 - val_accuracy: 0.8980 - val_loss: 0.3142\n",
      "Epoch 41/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8199 - loss: 0.3682 - val_accuracy: 0.8980 - val_loss: 0.3115\n",
      "Epoch 42/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8106 - loss: 0.3832 - val_accuracy: 0.8980 - val_loss: 0.3087\n",
      "Epoch 43/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8258 - loss: 0.3612 - val_accuracy: 0.8980 - val_loss: 0.3066\n",
      "Epoch 44/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8583 - loss: 0.3156 - val_accuracy: 0.8980 - val_loss: 0.3048\n",
      "Epoch 45/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8289 - loss: 0.3427 - val_accuracy: 0.8980 - val_loss: 0.3034\n",
      "Epoch 46/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8758 - loss: 0.2939 - val_accuracy: 0.8980 - val_loss: 0.3013\n",
      "Epoch 47/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8520 - loss: 0.3171 - val_accuracy: 0.9184 - val_loss: 0.2983\n",
      "Epoch 48/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8317 - loss: 0.3585 - val_accuracy: 0.8571 - val_loss: 0.3035\n",
      "Epoch 49/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8423 - loss: 0.3446 - val_accuracy: 0.8571 - val_loss: 0.3044\n",
      "Epoch 50/50\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8648 - loss: 0.3226 - val_accuracy: 0.8571 - val_loss: 0.3042\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Resultados con función Leaky ReLU:\n",
      "Accuracy: 0.8360655737704918\n",
      "Precision: 0.7333333333333333\n",
      "Recall: 0.6470588235294118\n",
      "F1 Score: 0.6875\n"
     ]
    }
   ],
   "source": [
    "model_leaky_relu = Sequential()\n",
    "model_leaky_relu.add(Dense(16))\n",
    "model_leaky_relu.add(LeakyReLU(alpha=0.1))\n",
    "model_leaky_relu.add(Dense(8))\n",
    "model_leaky_relu.add(LeakyReLU(alpha=0.1)) \n",
    "model_leaky_relu.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model_leaky_relu.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history_leaky_relu = model_leaky_relu.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "y_pred_leaky_relu = model_leaky_relu.predict(X_test)\n",
    "y_pred_classes_leaky_relu = (y_pred_leaky_relu > 0.5).astype(\"int32\")\n",
    "\n",
    "print('Resultados con función Leaky ReLU:')\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_pred_classes_leaky_relu)}')\n",
    "print(f'Precision: {precision_score(y_test, y_pred_classes_leaky_relu)}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_classes_leaky_relu)}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_classes_leaky_relu)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Proponer 2 modelos diferentes al modelo base y compárelos usando todas las métricas. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
